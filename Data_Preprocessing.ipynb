{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset directions\n",
    "Dataset_dir = r'D:\\Animation\\HWs\\02\\Dataset.npy'\n",
    "Dataset_max_len_Padded_dir = r'D:\\Animation\\HWs\\02\\Dataset_max_len_Padded.npy'\n",
    "Dataset_max_occ_len_Padded_dir = r'D:\\Animation\\HWs\\02\\Dataset_max_occ_len_Padded.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the dataset: 4016\n",
      "Number of columns in the dataset: 48\n"
     ]
    }
   ],
   "source": [
    "# Loading dataset\n",
    "Dataset = np.load(Dataset_dir)\n",
    "print('Number of rows in the dataset: %i' % (Dataset.shape[0]))\n",
    "print('Number of columns in the dataset: %i' % (Dataset.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "Dataset[:, 3:] = scaler.fit_transform(Dataset[:, 3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalization\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# sc = StandardScaler()\n",
    "# Dataset[:, 3:] = sc.fit_transform(Dataset[:, 3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set videos, actions and actors labels from zero\n",
    "for index in range(Dataset.shape[0]):\n",
    "    Dataset[index, 0] -= 1\n",
    "    Dataset[index, 1] -= 1\n",
    "    Dataset[index, 2] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "videos_len = Dataset[-1, 0].astype(int) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine maximum length and maximum occured length\n",
    "num_frames = np.bincount(Dataset[:, 0].astype(int))\n",
    "max_len = np.max(num_frames)\n",
    "max_occur_len = np.argmax(np.bincount(num_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence-Padding to reach all videos to length of max length\n",
    "def max_length_pad_sequence(dataset):\n",
    "    ds = np.copy(dataset)\n",
    "    for vid_index in range(videos_len):\n",
    "        start_index = vid_index * max_len\n",
    "        pad_length = max_len - num_frames[vid_index]\n",
    "        pad_mtx = np.zeros((pad_length, ds.shape[1]))\n",
    "        pad_mtx[:, 0:3] = ds[start_index, 0:3]\n",
    "        ds = np.insert(ds, start_index + num_frames[vid_index], pad_mtx, axis=0)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence-Padding to reach all videos to max occured length\n",
    "def max_occur_pad_sequence(dataset):\n",
    "    ds = np.copy(dataset)\n",
    "    for vid_index in range(videos_len):\n",
    "        end_index = (vid_index + 1) * max_occur_len\n",
    "        start_index = vid_index * max_occur_len\n",
    "        pad_length = max_occur_len - num_frames[vid_index]\n",
    "        if pad_length < 0:\n",
    "            for i in range(np.abs(pad_length)):\n",
    "                ds = np.delete(ds, end_index, axis=0)\n",
    "        else:\n",
    "            pad_mtx = np.zeros((pad_length, ds.shape[1]))\n",
    "            pad_mtx[:, 0:3] = ds[start_index, 0:3]\n",
    "            ds = np.insert(ds, start_index + num_frames[vid_index], pad_mtx, axis=0)\n",
    "                \n",
    "    return ds          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate padded datasets, in this datasets all sample videos have same length\n",
    "Dataset_max_len_pad_seq = max_length_pad_sequence(Dataset)\n",
    "Dataset_max_occ_pad_seq = max_occur_pad_sequence(Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset from max length sequence padding:\n",
      "Number of rows in the dataset: 7525\n",
      "Number of columns in the dataset: 48\n"
     ]
    }
   ],
   "source": [
    "# Dimensions of datasets after padding\n",
    "print('Dataset from max length sequence padding:')\n",
    "print('Number of rows in the dataset: %i' % (Dataset_max_len_pad_seq.shape[0]))\n",
    "print('Number of columns in the dataset: %i' % (Dataset_max_len_pad_seq.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset from max occurance length sequence padding:\n",
      "Number of rows in the dataset: 3440\n",
      "Number of columns in the dataset: 48\n"
     ]
    }
   ],
   "source": [
    "print('Dataset from max occurance length sequence padding:')\n",
    "print('Number of rows in the dataset: %i' % (Dataset_max_occ_pad_seq.shape[0]))\n",
    "print('Number of columns in the dataset: %i' % (Dataset_max_occ_pad_seq.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape of dataset: (215, 35, 48)\n",
      "New shape of dataset: (215, 16, 48)\n"
     ]
    }
   ],
   "source": [
    "# Reshape datasets to form (sample,timestep,features)\n",
    "Dataset_max_len_pad_seq = Dataset_max_len_pad_seq.reshape((videos_len, max_len, Dataset_max_len_pad_seq.shape[1]))\n",
    "print('New shape of dataset: ' + str(Dataset_max_len_pad_seq.shape))\n",
    "Dataset_max_occ_pad_seq = Dataset_max_occ_pad_seq.reshape((videos_len, max_occur_len, Dataset_max_occ_pad_seq.shape[1]))\n",
    "print('New shape of dataset: ' + str(Dataset_max_occ_pad_seq.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save new datasets to .npy file\n",
    "np.save(Dataset_max_len_Padded_dir, Dataset_max_len_pad_seq)\n",
    "np.save(Dataset_max_occ_len_Padded_dir, Dataset_max_occ_pad_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
